"""
threattracer.core.exploitdb
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Exploit-DB integration:
  - Downloads and locally indexes the official CSV
  - Matches by CVE ID in the 'codes' column
  - Fuzzy-matches by title similarity as fallback
  - Tags exploit type and platform
"""

from __future__ import annotations

import csv
import io
import logging
from pathlib import Path
from typing import Dict, List, Optional

from rapidfuzz import fuzz

from threattracer.utils.cache import ResponseCache
from threattracer.utils.config import AppConfig
from threattracer.utils.http_client import AsyncHTTPClient
from threattracer.utils.models import ExploitEntry

log = logging.getLogger(__name__)

# Where we persist the raw CSV between runs
_CSV_LOCAL = Path.home() / ".threattracer" / "exploitdb.csv"


class ExploitDBClient:
    """
    Fetches, caches, and queries the Exploit-DB CSV index.

    The CSV is stored locally and in the SQLite cache.
    Re-downloaded only when the SQLite TTL expires.
    """

    def __init__(
        self,
        config: AppConfig,
        http: AsyncHTTPClient,
        cache: ResponseCache,
    ) -> None:
        self._cfg = config
        self._http = http
        self._cache = cache
        self._index: Optional[Dict[str, dict]] = None

    async def _ensure_index(self) -> None:
        """Load the CSV index from cache → disk → network (in that order)."""
        if self._index is not None:
            return

        cache_key = "exploitdb:csv_index"
        cached = await self._cache.get(cache_key)
        if cached is not None:
            log.debug("ExploitDB index loaded from cache (%d entries)", len(cached))
            self._index = cached
            return

        # Try local disk first (faster than re-downloading on cold cache)
        raw_text: Optional[str] = None
        if _CSV_LOCAL.exists():
            log.debug("Loading ExploitDB CSV from disk: %s", _CSV_LOCAL)
            raw_text = _CSV_LOCAL.read_text(encoding="utf-8", errors="replace")
        else:
            log.info("Downloading ExploitDB CSV index…")
            raw_text = await self._http.get_text(self._cfg.exploitdb_csv_url)

        if not raw_text:
            log.error("Failed to obtain ExploitDB CSV")
            self._index = {}
            return

        # Persist to disk for offline access
        _CSV_LOCAL.parent.mkdir(parents=True, exist_ok=True)
        _CSV_LOCAL.write_text(raw_text, encoding="utf-8")

        self._index = self._parse_csv(raw_text)
        log.info("ExploitDB index built: %d entries", len(self._index))
        await self._cache.set(cache_key, self._index)

    @staticmethod
    def _parse_csv(raw: str) -> Dict[str, dict]:
        reader = csv.DictReader(io.StringIO(raw))
        index: Dict[str, dict] = {}
        for row in reader:
            exp_id = row.get("id", "").strip()
            if exp_id:
                index[exp_id] = row
        return index

    async def search_by_cve(self, cve_id: str) -> List[ExploitEntry]:
        """
        Return all Exploit-DB entries whose 'codes' column contains cve_id.
        Also does a secondary fuzzy-title check for partial matches.
        """
        await self._ensure_index()
        if not self._index:
            return []

        cve_lower = cve_id.lower()
        results: List[ExploitEntry] = []

        for exp_id, row in self._index.items():
            codes = row.get("codes", "").lower()
            title = row.get("description", "")

            # Primary: exact CVE-ID in codes field
            if cve_lower in codes:
                results.append(self._row_to_entry(exp_id, row))
                continue

            # Secondary: fuzzy title match as soft indicator (score > 85)
            title_score = fuzz.partial_ratio(cve_lower, title.lower())
            if title_score > 85:
                entry = self._row_to_entry(exp_id, row)
                results.append(entry)

        return results

    @staticmethod
    def _row_to_entry(exp_id: str, row: dict) -> ExploitEntry:
        return ExploitEntry(
            id=exp_id,
            description=row.get("description", "").strip(),
            link=f"https://www.exploit-db.com/exploits/{exp_id}",
            exploit_type=row.get("type", "").strip() or None,
            platform=row.get("platform", "").strip() or None,
        )

    async def sync(self) -> int:
        """Force re-download of the CSV and rebuild the index. Returns entry count."""
        if _CSV_LOCAL.exists():
            _CSV_LOCAL.unlink()
        self._index = None
        cache_key = "exploitdb:csv_index"
        await self._cache.delete(cache_key)
        await self._ensure_index()
        return len(self._index or {})
